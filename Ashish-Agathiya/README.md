### Project Overview

 Minimization of cost/loss function by Gradient Descent. [Batch GD and Stochastic GD].
It consists finding the parmeters/ coefficient of cost function by different Graddient Descent method. 
Reasons for performing regularization on our dataset before prediction. 
Relationship between Bias and Variance which leads to underfitting and overfir=tting of our dataset.

Regularization of data by various mthods by reducing its complexity by Lasso Regularization & Ridge Regularization.
Finding Hyperparameter which is assigned by us by Hold methidd and K fold cross validating which is followed by tuning of hyperprameters by Grid Search and  Random Search.
All the above system was applied to the Project where target value is the price whereas remianing features are independent features.


### Learnings from the project

 Approach I followed to solve the project is - 
1. Assign what is the target parameter and independent variable.
2. Divide the data into Train and Test Data.
3. Fit the data into different model.
4. Predicting target value and finding RMSE and R2 value  by Linear Regression, Lasso & Ridge regularization, Polynomial Regressor. 


### Approach taken to solve the problem

 Comparison of calculating mean square error and root mean squared value, r2 score by  different methods (Ridge Regularization, Lasso Regularization, Linear Regression,  Polynomial Regressor) and arriving at a good model which fits the data by comparing the results.


### Challenges faced

 Challenges faced while solving above project was  that the value by Lasso, Ridge and LR was approximately equal and therefore wasnt able to decide which model to be used.


### Additional pointers

 NA


